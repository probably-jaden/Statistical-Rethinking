[
  {
    "objectID": "forkingData.html",
    "href": "forkingData.html",
    "title": "Garden of Forking Data",
    "section": "",
    "text": "This Quarto document is made interactive using Observable JS. Interactive documents allow readers to modify parameters and see the results immediately. Learn more about OJS interactive documents at https://quarto.org/docs/interactive/ojs/."
  },
  {
    "objectID": "forkingData.html#observable-js",
    "href": "forkingData.html#observable-js",
    "title": "Garden of Forking Data",
    "section": "",
    "text": "This Quarto document is made interactive using Observable JS. Interactive documents allow readers to modify parameters and see the results immediately. Learn more about OJS interactive documents at https://quarto.org/docs/interactive/ojs/."
  },
  {
    "objectID": "forkingData.html#bubble-chart",
    "href": "forkingData.html#bubble-chart",
    "title": "Garden of Forking Data",
    "section": "Bubble Chart",
    "text": "Bubble Chart\nThis example uses a D3 bubble chart imported from Observable HQ to analyze commits to GitHub repositories.\nSelect a repository to analyze the commits of:\n\nlibrary(pdftools)\n\nUsing poppler version 23.04.0\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Extract text\ntext &lt;- pdf_text(\"~/Documents/Intellectual Fun/genericStats/p_hacking.pdf\")\n\n# Convert to tibble for manipulation\npdf_data &lt;- tibble(\n  page = seq_along(text),\n  content = text\n) %&gt;%\n  # Clean up common issues\n  mutate(\n    content = str_replace_all(content, \"\\\\s+\", \" \"),\n    content = str_trim(content)\n  )\n\nwriteLines(pdf_data$content, \"~/Documents/Intellectual Fun/genericStats/p_hacking.txt\")\n\nwrite_file(paste(pdf_data$content, collapse = \"\\n\\n\"), \"~/Documents/Intellectual Fun/genericStats/p_hacking.txt\")\n\n\nviewof repo = Inputs.radio(\n  [\n    \"pandas-dev/pandas\",\n    \"tidyverse/ggplot2\",\n  ], \n  { label: \"Repository:\", value: \"pandas-dev/pandas\"}\n)\n\n\n\n\n\n\nFetch the commits for the specified repo using the GitHub API:\n\nd3 = require('d3')\ncontributors = await d3.json(\n  \"https://api.github.com/repos/\" + repo + \"/stats/contributors\"\n)\ncommits = contributors.map(contributor =&gt; {\n  const author = contributor.author;\n  return {\n    name: author.login,\n    title: author.login,\n    group: author.type,\n    value: contributor.total\n  }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that the repo variable is bound dynamically from the radio input defined above. If you change the input the contributors query will be automatically re-executed.\nView the commits sorted by most to least:\n\nInputs.table(commits, { sort: \"value\", reverse: true })\n\n\n\n\n\n\nVisualize using a D3 bubble chart imported from Observable HQ:\n\nimport { chart } with { commits as data } \n  from \"@d3/d3-bubble-chart\"\nchart"
  },
  {
    "objectID": "ch4_linear_regression.html",
    "href": "ch4_linear_regression.html",
    "title": "ch4",
    "section": "",
    "text": "!khun"
  },
  {
    "objectID": "ch4_linear_regression.html#first-model",
    "href": "ch4_linear_regression.html#first-model",
    "title": "ch4",
    "section": "",
    "text": "!khun"
  },
  {
    "objectID": "ch4_linear_regression.html#eda-kung-height-weight-gender",
    "href": "ch4_linear_regression.html#eda-kung-height-weight-gender",
    "title": "ch4",
    "section": "EDA !Kung Height ~ Weight + Gender",
    "text": "EDA !Kung Height ~ Weight + Gender\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting the Prior\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrid approximation technique\n\nn &lt;- 200\n\nd_grid &lt;-\n  # we'll accomplish with `tidyr::crossing()` what McElreath did with base R `expand.grid()`\n  crossing(mu    = seq(from = 130, to = 180, length.out = n),\n           sigma = seq(from = 0,   to = 15,   length.out = n))\n\n\ngrid_function &lt;- function(mu, sigma) {\n  dnorm(kHeight_adult$height, mean = mu, sd = sigma, log = T) %&gt;% \n    sum()\n}\n\nd_grid &lt;-\n  d_grid %&gt;% \n  mutate(log_likelihood = map2(mu, sigma, grid_function)) %&gt;%\n  unnest(log_likelihood) %&gt;% \n  mutate(prior_mu    = dnorm(mu,    mean = 150, sd  = 10, log = T),\n         prior_sigma = dunif(sigma, min  = 0,   max = 10, log = T),\n         product = log_likelihood + prior_mu + prior_sigma,\n         probability = exp(product- max(product)),\n         prior_product = prior_mu + prior_sigma,\n         prior_probability = exp(prior_product - max(prior_product)))\n\nprior_grid &lt;- \n  tibble(prior_mu = log(rnorm(1e5, mean = 150, sd = 10)),\n         prior_sigma = log(runif(1e5, min = 0, max = 10))) %&gt;% \n  mutate(product = prior_mu + prior_sigma,\n         probability = exp(product - max(product)))\n\nprior_plot &lt;- ggplot(data = d_grid) +\n  geom_point(aes(x = mu, y = sigma, color = prior_probability), alpha = .1) +\n  theme(panel.grid = element_blank()) +\n  scale_color_viridis_c(name = \"Prior Probability\", option = \"A\") +\n  labs(title = \"Prior\")\n  \nposterior_plot &lt;- ggplot(data = d_grid) +\n  geom_point(aes(x = mu, y = sigma, color = probability), alpha = .5) +\n   theme(panel.grid = element_blank()) +\n  scale_color_viridis_c(name = \"Posterior Probability\",  option = \"A\") +\n  labs(title = \"Posterior\")\n\nprior_plot + posterior_plot + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\nggplot(d_grid) +\n  geom_point(aes(x = mu, y = sigma, color = \"Prior\", alpha = prior_probability)) +\n  geom_point(aes(x = mu, y = sigma, color = \"Posterior\", alpha = probability)) +\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Posterior\" = \"red\")) +\n  scale_alpha(name = \"Normalized Likelihood\", range = c(0, 0.6)) +\n  labs(title = \"Prior vs Posterior\", color = \"Distribution\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nSample from the Posterior\n\nd_grid_samples &lt;- \n  d_grid %&gt;% \n  sample_n(size = 1e4, replace = T, weight = probability)\n\nd_grid_samples %&gt;% \n  ggplot(aes(x = mu, y = sigma)) + \n  geom_point(size = 0.9, alpha = 1/15) +\n  scale_fill_viridis_c() +\n  labs(x = expression(mu[samples]),\n       y = expression(sigma[samples])) +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\n\nmodel intercept only\n\nb4.1 &lt;- \n  brm(data = kHeight_adult, \n      family = gaussian,\n      height ~ 1,\n      prior = c(prior(normal(178, 20), class = Intercept),\n                prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      backend = \"cmdstanr\", seed = 4, file = \"fits/b04.011\")\n\nplot(b4.1) \n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.7 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nThe following objects are masked from 'package:posterior':\n\n    ess_bulk, ess_tail\n\n\n\n\n\n\n\n\n\n\nExtremely Narrow Priors\n\nb4.2 &lt;- \n  brm(data = kHeight_adult, family = gaussian,\n      height ~ 1,\n      prior = c(prior(normal(150, 2), class = Intercept),\n                prior(uniform(0, 6), class = sigma, lb = 0, ub = 6)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4, backend = \"cmdstanr\", silent = 2,\n      file = \"fits/b04.02.6\")\n\nplot(b4.2)\n\n\n\n\n\n\n\nb4.2_draws &lt;- as_draws_df(b4.2)\n\n\nb4.2_draws &lt;- b4.2_draws %&gt;% \n  mutate(prior_mu = rnorm(n(), 150, 2),\n         prior_sigma = runif(n(), 0, 6))\n\nggplot(b4.2_draws, ) +\n  geom_point(aes(x = b_Intercept, y = sigma), alpha = 0.05, color = \"blue\") +\n  geom_density_2d(aes(x = b_Intercept, y = sigma), color = \"blue\", bins = 5) +\n  geom_point(aes(x = prior_mu, y = prior_sigma), alpha = 0.05, color = \"red\") +\n  geom_density_2d(aes(x = prior_mu, y = prior_sigma), color = \"red\", bins = 5) +\n  labs(x = expression(mu), y = expression(sigma),\n       title = \"Posterior Contours of mu and sigma\") +\n  theme_minimal()"
  },
  {
    "objectID": "ch4_linear_regression.html#adding-linear-predictor",
    "href": "ch4_linear_regression.html#adding-linear-predictor",
    "title": "ch4",
    "section": "Adding Linear Predictor",
    "text": "Adding Linear Predictor\n\nkHeight_adult &lt;- \n  kHeight_adult %&gt;%\n  mutate(weight_c = weight - mean(weight))\n\nb4.3 &lt;- \n  brm(data = kHeight_adult, \n      family = gaussian,\n      height ~ 1 + weight_c,\n      prior = c(prior(normal(178, 100), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4, backend = \"cmdstanr\", silent = 2,\n      file = \"fits/b04.03.2\")\n\nas_draws_df(b4.3) %&gt;%\n  select(b_Intercept:sigma) %&gt;%\n  cor() %&gt;%\n  round(digits = 2)\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n            b_Intercept b_weight_c sigma\nb_Intercept        1.00      -0.04  0.02\nb_weight_c        -0.04       1.00  0.01\nsigma              0.02       0.01  1.00\n\npairs(b4.3)\n\n\n\n\n\n\n\n\n\nmu &lt;- fitted(b4.3, summary = F)\n\n# new data\nweight_seq &lt;- tibble(weight_c = seq(from = -18, to = 18, by = 1))\n\nmu &lt;-\n  fitted(b4.3,\n         summary = F,\n         newdata = weight_seq) %&gt;%\n  as_tibble() %&gt;%\n  # here we name the columns after the `weight` values from which they were computed\n  set_names(-18:18) %&gt;% \n  mutate(iter = 1:n())\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\nmu &lt;-  mu %&gt;%\n  gather(weight, height, -iter) %&gt;% \n  # we might reformat `weight` to numerals\n  mutate(weight = as.numeric(weight))\n\nggplot()+\n  geom_point(data = mu, aes(x = weight, y = height), alpha = .002, color = \"blue\")+\n  geom_point(data = kHeight_adult, aes(x = weight_c, y = height))\n\n\n\n\n\n\n\n\n\nplot prediction error\n\npred_height &lt;-\n  predict(b4.3,\n          newdata = weight_seq) %&gt;%\n  as_tibble() %&gt;%\n  bind_cols(weight_seq)\n  \npred_height %&gt;%\n  slice(1:6)\n\n# A tibble: 6 × 5\n  Estimate Est.Error  Q2.5 Q97.5 weight_c\n     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     138.      5.21  128.  148.      -18\n2     139.      5.14  129.  149.      -17\n3     140.      5.19  130.  150.      -16\n4     141.      5.13  131.  151.      -15\n5     142.      5.27  132.  152.      -14\n6     143.      5.00  133.  153.      -13"
  },
  {
    "objectID": "ch4_linear_regression.html#model-and-plot-quadratic-kung-height",
    "href": "ch4_linear_regression.html#model-and-plot-quadratic-kung-height",
    "title": "ch4",
    "section": "model and plot Quadratic !Kung height",
    "text": "model and plot Quadratic !Kung height\n\nkHeight &lt;-\n  kHeight %&gt;%\n  mutate(weight_s = (weight - mean(weight)) / sd(weight))\n\nb4.5 &lt;- \n  brm(data = kHeight, \n      family = gaussian,\n      height ~ 1 + weight_s + I(weight_s^2),\n      prior = c(prior(normal(178, 100), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      backend = \"cmdstanr\", silent = 2, seed = 4,\n      file = \"fits/b04.05.1.1\")\n\nweight_seq &lt;- tibble(weight_s = seq(from = min(kHeight$weight_s) - (0.5 * sd(kHeight$weight_s)),\n                                    to = max(kHeight$weight_s) + (0.5 * sd(kHeight$weight_s)), \n                                    length.out = 30))\n\nf &lt;-\n  fitted(b4.5, \n         newdata = weight_seq) %&gt;%\n  as_tibble() %&gt;%\n  bind_cols(weight_seq)\n\np &lt;-\n  predict(b4.5, \n          newdata = weight_seq) %&gt;%\n  as_tibble() %&gt;%\n  bind_cols(weight_seq) \n\nggplot(data = kHeight, \n       aes(x = weight_s)) +\n  geom_ribbon(data = p, \n              aes(ymin = Q2.5, ymax = Q97.5),\n              fill = \"grey83\") +\n  geom_smooth(data = f,\n              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),\n              stat = \"identity\",\n              fill = \"grey70\", color = \"black\", alpha = 1, linewidth = 1/2) +\n  geom_point(aes(y = height),\n             color = \"navyblue\", shape = 1, size = 1.5, alpha = 1/3) +\n  coord_cartesian(xlim = range(kHeight$weight_s)) +\n  theme(text = element_text(family = \"Times\"),\n        panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\npolynomial (Cubic) model !Kung height\n\nb4.6 &lt;- \n  brm(data = kHeight, \n      family = gaussian,\n      height ~ 1 + weight_s + I(weight_s^2) + I(weight_s^3),\n      prior = c(prior(normal(178, 100), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      backend = \"cmdstanr\", silent = 2,\n      seed = 4,\n      file = \"fits/b04.06\")\n\n\n# can't remember why I fit this model, I don't remember it being in the book\nb4.7 &lt;- \n  brm(data = kHeight, \n      family = gaussian,\n      height ~ 1 + weight_s,\n      prior = c(prior(normal(178, 100), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      backend = \"cmdstanr\", silent = 2,\n      seed = 4,\n      file = \"fits/b04.07\")\n\nf &lt;-\n  fitted(b4.6, \n         newdata = weight_seq) %&gt;%\n  as_tibble() %&gt;%\n  bind_cols(weight_seq)\n\np &lt;-\n  predict(b4.6, \n          newdata = weight_seq) %&gt;%\n  as_tibble() %&gt;%\n  bind_cols(weight_seq) \n\n\n\nplot Polynomial (Cubic) !Kung height\n\nat &lt;- c(-2, -1, 0, 1, 2)\nggplot(data = kHeight, \n       aes(x = weight_s)) +\n  geom_ribbon(data = p, \n              aes(ymin = Q2.5, ymax = Q97.5),\n              fill = \"grey83\") +\n  geom_smooth(data = f,\n              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),\n              stat = \"identity\",\n              fill = \"grey70\", color = \"black\", alpha = 1, linewidth = 1/4) +\n  geom_point(aes(y = height),\n             color = \"navyblue\", shape = 1, size = 1.5, alpha = 1/3) +\n  coord_cartesian(xlim = range(kHeight$weight_s)) +\n  theme_minimal()+\n  \n  # here it is!\n  scale_x_continuous(\"standardized weight converted back\",\n                     breaks = at,\n                     labels = round(at * sd(kHeight$weight) + mean(kHeight$weight), 1))"
  },
  {
    "objectID": "ch4_linear_regression.html#splines",
    "href": "ch4_linear_regression.html#splines",
    "title": "ch4",
    "section": "Splines!",
    "text": "Splines!\n\nEDA cherry blossom data\n\nlibrary(rethinking)\n\nrethinking (Version 2.42)\n\n\n\nAttaching package: 'rethinking'\n\n\nThe following objects are masked from 'package:rstan':\n\n    stan, traceplot\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n\nThe following objects are masked from 'package:brms':\n\n    LOO, stancode, WAIC\n\n\nThe following object is masked from 'package:stats':\n\n    rstudent\n\nggplot(data = cherry, aes(x = year, y = temp))+geom_line()+labs(title = \"Cherry Blossom temperature in March)\")\n\nWarning: Removed 73 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\nSpline Model Cherry Blossom\n\ncherry2 &lt;- cherry %&gt;% \n  filter(!is.na(temp))\n\nnum_knots &lt;- 15\nknot_list &lt;- quantile( cherry2$year, probs=seq(0,1,length.out=num_knots) )\n\n\nB &lt;- bs(cherry2$year,\n    knots=knot_list[-c(1,num_knots)] ,\n    degree=4 , intercept=TRUE )\n\nB_tib &lt;- as_tibble(B) \n\n\nB_tib_join &lt;- cbind(cherry2, B_tib)\n\nB_tib_join_long &lt;- B_tib_join %&gt;% \n  pivot_longer(cols = c(`1`, `2`,`3`, `4`,`5`, `6`,`7`, `8`,`9`, `10`,`11`, `12`,`13`, `14`, `15`, `16`, `17`),\n               names_to = \"knot\",\n               values_to = \"density\")\n\nggplot(data = B_tib_join_long, aes(x = year, y = (density),  color = as.factor(knot)))+geom_line()\n\nDon't know how to automatically pick scale for object of type\n&lt;bs/basis/matrix&gt;. Defaulting to continuous.\n\n\n\n\n\n\n\n\nb4_smooth &lt;- brm(\n  data = cherry2,\n  family = gaussian,\n  formula = temp ~ 1 + s(year, bs = \"bs\", k = 30),  # k sets number of basis functions\n  prior = c(\n    prior(normal(6, 10), class = Intercept),\n    prior(normal(0, 1), class = b),\n    prior(student_t(3, 0, 1), class = sds),      # Prior for smooth term\n    prior(exponential(1), class = sigma)\n  ),\n  backend = \"cmdstanr\", silent = 2,\n  iter = 2000,\n  warmup = 1000,\n  chains = 4,\n  cores = 4,\n  seed = 42,\n  control = list(adapt_delta = 0.99),\n  file = \"fits/b04.cherry_bspline\"\n)\n\nb4.1_smooth &lt;- brm(\n  data = cherry2,\n  family = gaussian,\n  formula = temp ~ 1 + s(year, bs = \"tp\"),  # k sets number of basis functions\n  prior = c(\n    prior(normal(6, 10), class = Intercept),\n    prior(normal(0, 1), class = b),\n    prior(student_t(3, 0, 1), class = sds),      # Prior for smooth term\n    prior(exponential(1), class = sigma)\n  ),\n  backend = \"cmdstanr\", silent = 2,\n  iter = 2000,\n  warmup = 1000,\n  chains = 4,\n  cores = 4,\n  seed = 42,\n  control = list(adapt_delta = 0.99),\n  file = \"fits/b04.cherry_thinSpline\"\n)\n\n\nyear_seq &lt;- tibble(year = seq(from = 800, to = 2000, by = 10))\n\nmu_temp_4 &lt;-\n  fitted(b4_smooth, \n         newdata = year_seq) %&gt;%\n  as_tibble() %&gt;%\n  # let's tack on the `weight` values from `weight_seq`\n  bind_cols(year_seq)\n\npred_temp_4 &lt;-\n  predict(b4_smooth,\n          newdata = year_seq) %&gt;%\n  as_tibble() %&gt;%\n  bind_cols(year_seq)\n  \n# pred_temp_4 %&gt;%\n#   slice(1:6)\n\n\nmu_temp_4.1 &lt;-\n  fitted(b4.1_smooth, \n         newdata = year_seq) %&gt;%\n  as_tibble() %&gt;%\n  # let's tack on the `weight` values from `weight_seq`\n  bind_cols(year_seq)\n\npred_temp_4.1 &lt;-\n  predict(b4.1_smooth,\n          newdata = year_seq) %&gt;%\n  as_tibble() %&gt;%\n  bind_cols(year_seq)\n  \n# pred_temp_4.1 %&gt;%\n#   slice(1:6)\n\n\n\nPlots Cherry Blossom\n\ncherry2 %&gt;%\n  ggplot(aes(x = year)) +\n  geom_ribbon(data = pred_temp_4, \n              aes(ymin = Q2.5, ymax = Q97.5),\n              fill = \"grey83\") +\n  geom_smooth(data = mu_temp_4,\n              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),\n              stat = \"identity\",\n              fill = \"grey70\", color = \"black\", alpha = 1, linewidth = 1/2) +\n  geom_point(aes(y = temp),\n             color = \"navyblue\", shape = 1, size = 1.5, alpha = 2/3) +\n  ylab(\"temp\") +\n  labs(title = \"15 knot B-splines\")\n\n\n\n\n\n\n\ncherry2 %&gt;%\n  ggplot(aes(x = year)) +\n  geom_ribbon(data = pred_temp_4.1, \n              aes(ymin = Q2.5, ymax = Q97.5),\n              fill = \"grey83\") +\n  geom_smooth(data = mu_temp_4.1,\n              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),\n              stat = \"identity\",\n              fill = \"grey70\", color = \"black\", alpha = 1, linewidth = 1/2) +\n  geom_line(aes(y = temp),\n             color = \"navyblue\", shape = 1) +\n  ylab(\"temp\") +\n  labs(title = \"Thin Plated Spline\")\n\nWarning in geom_line(aes(y = temp), color = \"navyblue\", shape = 1): Ignoring\nunknown parameters: `shape`\n\n\n\n\n\n\n\n\n# I am confused as to why the the Thin plated splines don't go more crazy and try to fit all of the contours"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Rethinking Homepage",
    "section": "",
    "text": "Welcome\nThis site showcases projects from my Statistical Rethinking work in R and Quarto.\n\n📈 Linear Regression\n\n🔀 Forking Paths\n\nSource code is on GitHub."
  }
]