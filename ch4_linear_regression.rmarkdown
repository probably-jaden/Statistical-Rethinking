---
title: "ch4"
format: html
editor: visual
---



## 4.3.1 First Model 

!khun



```{r}
library(rethinking)
data(Howell1)
d <- Howell1

rm(Howell1)
detach(package:rethinking, unload = T)
library(brms)
library(tidyverse)

setwd("~/Documents/Intellectual Fun/statisticalRethinking/statisticalRethinking")

```

```{r}
d2 <- d %>%
  filter(age >= 18)

d3 <- d %>%
  filter(age < 18)

ggplot(data = d2, aes(x = height, y = weight, color = as.factor(male)))+geom_point(alpha = .7)
```



### Plotting the Prior 



```{r}

# mean prior
ggplot(data = tibble(x = seq(from = 100, to = 250, by = .1)), 
       aes(x = x, y = dnorm(x, mean = 178, sd = 20))) +
  scale_y_continuous(NULL, breaks = NULL) +
  geom_line() +
  ylab("density")

# posterior distribution of height prior and mean
n <- 1e5
tibble(sample_mu    = rnorm(n, mean = 178,       sd  = 20),
       sample_sigma = runif(n, min  = 0,         max = 50)) %>% 
  mutate(x = rnorm(n, mean = sample_mu, sd  = sample_sigma)) %>% 
  ggplot() +
  geom_density(aes(x = x), color = "black", linewidth = 1, adjust = 2) +
  geom_density(aes(x = sample_mu), color = "red", linewidth = 1, adjust = 2) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = expression(Prior~predictive~distribution~"for"~italic(h[i])),
       x = NULL) +
  theme(panel.grid = element_blank())
```



### Grid approximation technique



```{r}
n <- 200

d_grid <-
  # we'll accomplish with `tidyr::crossing()` what McElreath did with base R `expand.grid()`
  crossing(mu    = seq(from = 140, to = 160, length.out = n),
           sigma = seq(from = 4,   to = 9,   length.out = n))

glimpse(d_grid)

ggplot(data = d_grid)+geom_point(aes(x = mu, y = sigma), alpha = .1)

grid_function <- function(mu, sigma) {
  dnorm(d2$height, mean = mu, sd = sigma, log = T) %>% 
    sum()
}

d_grid <-
  d_grid %>% 
  mutate(log_likelihood = map2(mu, sigma, grid_function)) %>%
  unnest(log_likelihood) %>% 
  mutate(prior_mu    = dnorm(mu,    mean = 178, sd  = 20, log = T),
         prior_sigma = dunif(sigma, min  = 0,   max = 50, log = T)) %>% 
  mutate(product = log_likelihood + prior_mu + prior_sigma) %>% 
  mutate(probability = exp(product- max(product)))

ggplot(data = d_grid)+geom_point(aes(x = mu, y = sigma, color = probability), alpha = .5)+
   theme(panel.grid = element_blank())+
  scale_color_viridis_c(option = "A") 

hist(exp(d_grid$prior_sigma))


```



### Sample from the Posterior 



```{r}
d_grid_samples <- 
  d_grid %>% 
  sample_n(size = 1e4, replace = T, weight = probability)

d_grid_samples %>% 
  ggplot(aes(x = mu, y = sigma)) + 
  geom_point(size = 0.9, alpha = 1/15) +
  scale_fill_viridis_c() +
  labs(x = expression(mu[samples]),
       y = expression(sigma[samples])) +
  theme(panel.grid = element_blank())


#prior vs posterior sigma
ggplot()+
  geom_density(data = d_grid_samples, aes(x = (sigma)), color = "red", linewidth = 1, adjust = 2)+
  geom_density(data = tibble(sigma = runif(nrow(d_grid_samples), 0, 50)), aes(x = sigma), color = "black", linewidth = 1, adjust = 2)


```



### Modeling with BRMS



```{r}
b4.1 <- 
  brm(data = d2, 
      family = gaussian,
      height ~ 1,
      prior = c(prior(normal(178, 20), class = Intercept),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      backend = "cmdstanr", seed = 4, file = "fits/b04.011")

plot(b4.1) 
```



#### Extremely Narrow Priors



```{r}

b4.2 <- 
  brm(data = d2, family = gaussian,
      height ~ 1,
      prior = c(prior(normal(178, 20), class = Intercept),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 4, backend = "cmdstanr", silent = 2,
      file = "fits/b04.02.5")

plot(b4.2)

b4.2_draws <- as_draws_df(b4.2)


ggplot(data = b4.2_draws)+geom_point(aes(x = Intercept, y = sigma), alpha = .2)+
   theme(panel.grid = element_blank())


 
```



## Adding Linear Predictor



```{r}

d2 <- 
  d2 %>%
  mutate(weight_c = weight - mean(weight))

b4.3 <- 
  brm(data = d2, 
      family = gaussian,
      height ~ 1 + weight_c,
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 4, backend = "cmdstanr", silent = 2,
      file = "fits/b04.03.2")

as_draws_df(b4.3) %>%
  select(b_Intercept:sigma) %>%
  cor() %>%
  round(digits = 2)

pairs(b4.3)
```

```{r}
mu <- fitted(b4.3, summary = F)

# new data
weight_seq <- tibble(weight_c = seq(from = -18, to = 18, by = 1))

mu <-
  fitted(b4.3,
         summary = F,
         newdata = weight_seq) %>%
  as_tibble() %>%
  # here we name the columns after the `weight` values from which they were computed
  set_names(-18:18) %>% 
  mutate(iter = 1:n())

mu <-  mu %>%
  gather(weight, height, -iter) %>% 
  # we might reformat `weight` to numerals
  mutate(weight = as.numeric(weight))

ggplot()+
  geom_point(data = mu, aes(x = weight, y = height), alpha = .002, color = "blue")+
  geom_point(data = d2, aes(x = weight_c, y = height))
 
  


```



#### With Prediction Error



```{r}
pred_height <-
  predict(b4.3,
          newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq)
  
pred_height %>%
  slice(1:6)
```



## model and plot Quadratic !Kung height



```{r model and plot quadratic kung height}
d <-
  d %>%
  mutate(weight_s = (weight - mean(weight)) / sd(weight))

b4.5 <- 
  brm(data = d, 
      family = gaussian,
      height ~ 1 + weight_s + I(weight_s^2),
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      backend = "cmdstanr", silent = 2, seed = 4,
      file = "fits/b04.05.1")

weight_seq <- tibble(weight_s = seq(from = min(d$weight_s) - (0.5 * sd(d$weight_s)),
                                    to = max(d$weight_s) + (0.5 * sd(d$weight_s)), 
                                    length.out = 30))

f <-
  fitted(b4.5, 
         newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq)

p <-
  predict(b4.5, 
          newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq) 

ggplot(data = d, 
       aes(x = weight_s)) +
  geom_ribbon(data = p, 
              aes(ymin = Q2.5, ymax = Q97.5),
              fill = "grey83") +
  geom_smooth(data = f,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              fill = "grey70", color = "black", alpha = 1, linewidth = 1/2) +
  geom_point(aes(y = height),
             color = "navyblue", shape = 1, size = 1.5, alpha = 1/3) +
  coord_cartesian(xlim = range(d$weight_s)) +
  theme(text = element_text(family = "Times"),
        panel.grid = element_blank())
```



### polynomial (Cubic) model !Kung height


```{r Model polynomial kung height}
b4.6 <- 
  brm(data = d, 
      family = gaussian,
      height ~ 1 + weight_s + I(weight_s^2) + I(weight_s^3),
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      backend = "cmdstanr", silent = 2,
      seed = 4,
      file = "fits/b04.06")


# can't remember why I fit this model, I don't remember it being in the book
b4.7 <- 
  brm(data = d, 
      family = gaussian,
      height ~ 1 + weight_s,
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      backend = "cmdstanr", silent = 2,
      seed = 4,
      file = "fits/b04.07")

f <-
  fitted(b4.6, 
         newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq)

p <-
  predict(b4.6, 
          newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq) 

```



### plot Polynomial (Cubic) !Kung height


```{r plot height cubic polynomial}

at <- c(-2, -1, 0, 1, 2)
ggplot(data = d, 
       aes(x = weight_s)) +
  geom_ribbon(data = p, 
              aes(ymin = Q2.5, ymax = Q97.5),
              fill = "grey83") +
  geom_smooth(data = f,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              fill = "grey70", color = "black", alpha = 1, linewidth = 1/4) +
  geom_point(aes(y = height),
             color = "navyblue", shape = 1, size = 1.5, alpha = 1/3) +
  coord_cartesian(xlim = range(d$weight_s)) +
  theme_minimal()+
  
  # here it is!
  scale_x_continuous("standardized weight converted back",
                     breaks = at,
                     labels = round(at * sd(d$weight) + mean(d$weight), 1))
```



## Splines!

### EDA cherry blossom data



```{r EDA cherry blossoms}
library(rethinking)
data("cherry_blossoms")
cherry <- cherry_blossoms
cherry

ggplot(data = cherry, aes(x = year, y = temp))+geom_line()+labs(title = "Cherry Blossom temperature in March)")
  

```


### Spline Model Cherry Blossom   



```{r Model Creation cherry}
cherry2 <- cherry %>% 
  filter(!is.na(temp))

num_knots <- 15
knot_list <- quantile( cherry2$year, probs=seq(0,1,length.out=num_knots) )

library(splines)
B <- bs(cherry2$year,
    knots=knot_list[-c(1,num_knots)] ,
    degree=4 , intercept=TRUE )

B_tib <- as_tibble(B) 


B_tib_join <- cbind(cherry2, B_tib)

B_tib_join_long <- B_tib_join %>% 
  pivot_longer(cols = c(`1`, `2`,`3`, `4`,`5`, `6`,`7`, `8`,`9`, `10`,`11`, `12`,`13`, `14`, `15`, `16`, `17`),
               names_to = "knot",
               values_to = "density")

ggplot(data = B_tib_join_long, aes(x = year, y = (density),  color = as.factor(knot)))+geom_line()



b4_smooth <- brm(
  data = cherry2,
  family = gaussian,
  formula = temp ~ 1 + s(year, bs = "bs", k = 30),  # k sets number of basis functions
  prior = c(
    prior(normal(6, 10), class = Intercept),
    prior(normal(0, 1), class = b),
    prior(student_t(3, 0, 1), class = sds),      # Prior for smooth term
    prior(exponential(1), class = sigma)
  ),
  backend = "cmdstanr", silent = 2,
  iter = 2000,
  warmup = 1000,
  chains = 4,
  cores = 4,
  seed = 42,
  control = list(adapt_delta = 0.99)
)

b4.1_smooth <- brm(
  data = cherry2,
  family = gaussian,
  formula = temp ~ 1 + s(year, bs = "tp"),  # k sets number of basis functions
  prior = c(
    prior(normal(6, 10), class = Intercept),
    prior(normal(0, 1), class = b),
    prior(student_t(3, 0, 1), class = sds),      # Prior for smooth term
    prior(exponential(1), class = sigma)
  ),
  backend = "cmdstanr", silent = 2,
  iter = 2000,
  warmup = 1000,
  chains = 4,
  cores = 4,
  seed = 42,
  control = list(adapt_delta = 0.99)
)


year_seq <- tibble(year = seq(from = 800, to = 2000, by = 1))

mu_temp_4 <-
  fitted(b4_smooth, 
         newdata = year_seq) %>%
  as_tibble() %>%
  # let's tack on the `weight` values from `weight_seq`
  bind_cols(year_seq)

pred_temp_4 <-
  predict(b4_smooth,
          newdata = year_seq) %>%
  as_tibble() %>%
  bind_cols(year_seq)
  
# pred_temp_4 %>%
#   slice(1:6)


mu_temp_4.1 <-
  fitted(b4.1_smooth, 
         newdata = year_seq) %>%
  as_tibble() %>%
  # let's tack on the `weight` values from `weight_seq`
  bind_cols(year_seq)

pred_temp_4.1 <-
  predict(b4.1_smooth,
          newdata = year_seq) %>%
  as_tibble() %>%
  bind_cols(year_seq)
  
# pred_temp_4.1 %>%
#   slice(1:6)

```



###  Plots Cherry Blossom



```{r Visuals cherry}
cherry2 %>%
  ggplot(aes(x = year)) +
  geom_ribbon(data = pred_temp_4, 
              aes(ymin = Q2.5, ymax = Q97.5),
              fill = "grey83") +
  geom_smooth(data = mu_temp_4,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              fill = "grey70", color = "black", alpha = 1, linewidth = 1/2) +
  geom_point(aes(y = temp),
             color = "navyblue", shape = 1, size = 1.5, alpha = 2/3) +
  ylab("temp") +
  labs(title = "15 knot B-splines")

cherry2 %>%
  ggplot(aes(x = year)) +
  geom_ribbon(data = pred_temp_4.1, 
              aes(ymin = Q2.5, ymax = Q97.5),
              fill = "grey83") +
  geom_smooth(data = mu_temp_4.1,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              fill = "grey70", color = "black", alpha = 1, linewidth = 1/2) +
  geom_line(aes(y = temp),
             color = "navyblue", shape = 1) +
  ylab("temp") +
  labs(title = "Thin Plated Spline")

# I am confused as to why the the Thin plated splines don't go more crazy and try to fit all of the contours 




```



# Hard Questions

### 4H1
The weights listed below were recorded in the !Kung census,but heights were not recorded for these individuals. Provide predicted heights and 89% intervals for each of these individuals. That is, fill in the table below, using model-based predictions.



```{r}

```

